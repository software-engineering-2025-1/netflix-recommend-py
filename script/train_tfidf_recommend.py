# ê°œì„ ëœ ë„·í”Œë¦­ìŠ¤ ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ: ê³ ì„±ëŠ¥ TF-IDF ë²¡í„°ë¼ì´ì €

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import joblib
import re
from collections import Counter
import os

def preprocess_dataframe(df):
    """Unnamed ì»¬ëŸ¼ ì œê±°"""
    delete_columns = [i for i in df.columns if 'Unnamed' in i]
    df.drop(columns=delete_columns, inplace=True)
    return df

def preprocess_text(text):
    """ê³ ê¸‰ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    if pd.isna(text):
        return ""
    
    text = str(text).lower()
    # êµ¬ë‘ì  ë° íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•˜ì´í”ˆì€ ìœ ì§€)
    text = re.sub(r'[^\w\s-]', ' ', text)
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì••ì¶•
    text = re.sub(r'\s+', ' ', text)
    # ìˆ«ìë§Œ ìˆëŠ” ë‹¨ì–´ ì œê±°
    text = re.sub(r'\b\d+\b', '', text)
    # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ ì œê±° (2ê¸€ì ì´í•˜)
    words = [word for word in text.split() if len(word) > 2]
    
    return ' '.join(words).strip()

def create_enhanced_tags(row):
    """SBERTì™€ ë™ì¼í•œ ê°€ì¤‘ì¹˜ ê¸°ë°˜ íƒœê·¸ ìƒì„± (ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´)"""
    tags = []
    
    # ì¥ë¥´ (ê°€ì¤‘ì¹˜ 3ë°°) - ì¶”ì²œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±
    if pd.notnull(row.get('listed_in')):
        genres = [genre.strip().lower().replace(' ', '_') for genre in row['listed_in'].split(',')]
        # ì¥ë¥´ë¥¼ 3ë²ˆ ë°˜ë³µí•´ì„œ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        tags.extend(genres * 3)
    
    # ì œëª© (ê°€ì¤‘ì¹˜ 2ë°°) - ì œëª©ì˜ í‚¤ì›Œë“œë„ ì¤‘ìš”
    if pd.notnull(row.get('title')):
        title_words = preprocess_text(row['title']).split()
        tags.extend(title_words * 2)
    
    # ì„¤ëª… (ê°€ì¤‘ì¹˜ 1ë°°) - ì „ì²˜ë¦¬ëœ ì„¤ëª…
    if pd.notnull(row.get('description')):
        desc_processed = preprocess_text(row['description'])
        # ì„¤ëª…ì—ì„œ ì¤‘ìš”í•œ ë‹¨ì–´ë“¤ë§Œ ì¶”ì¶œ (ê¸´ ì„¤ëª…ì€ ë…¸ì´ì¦ˆê°€ ë  ìˆ˜ ìˆìŒ)
        desc_words = desc_processed.split()[:50]  # ì²« 50ê°œ ë‹¨ì–´ë§Œ ì‚¬ìš©
        tags.extend(desc_words)
    
    # ê°ë… (ê°€ì¤‘ì¹˜ 2ë°°) - ê°ë… ìŠ¤íƒ€ì¼ì´ ì¤‘ìš”
    if pd.notnull(row.get('director')):
        director_name = preprocess_text(row['director']).replace(' ', '_')
        if director_name:
            tags.extend([director_name] * 2)
    
    # ì£¼ìš” ë°°ìš° (ê°€ì¤‘ì¹˜ 2ë°°) - ìƒìœ„ 3ëª…
    if pd.notnull(row.get('cast')):
        actors = [actor.strip() for actor in str(row['cast']).split(',')[:3]]
        for actor in actors:
            actor_processed = preprocess_text(actor).replace(' ', '_')
            if actor_processed:
                tags.extend([actor_processed, actor_processed])  # 2ë²ˆ ë°˜ë³µìœ¼ë¡œ ê°€ì¤‘ì¹˜ íš¨ê³¼
    
    # êµ­ê°€ (ê°€ì¤‘ì¹˜ 1ë°°)
    if pd.notnull(row.get('country')):
        countries = [country.strip().lower().replace(' ', '_') for country in str(row['country']).split(',')]
        tags.extend(countries)
    
    # íƒ€ì… (Movie/TV Show) ì¶”ê°€
    if pd.notnull(row.get('type')):
        content_type = row['type'].lower().replace(' ', '_')
        tags.extend([content_type] * 2)
    
    # ì—°ë„ëŒ€ ì •ë³´ ì¶”ê°€ (10ë…„ ë‹¨ìœ„)
    if pd.notnull(row.get('release_year')):
        decade = f"decade_{int(row['release_year']) // 10 * 10}s"
        tags.append(decade)
    
    # ëª¨ë“  íƒœê·¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ì •ë¦¬
    clean_tags = [str(tag) for tag in tags if tag and str(tag).strip()]
    
    return ' '.join(clean_tags)

def get_enhanced_stopwords():
    """ì˜í™” ë„ë©”ì¸ íŠ¹í™” ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸"""
    # ê¸°ë³¸ ì˜ì–´ ë¶ˆìš©ì–´ + ì˜í™” ë„ë©”ì¸ íŠ¹í™” ë¶ˆìš©ì–´
    movie_stopwords = [
        'movie', 'film', 'story', 'character', 'plot', 'scene', 'series',
        'show', 'episode', 'season', 'cast', 'starring', 'directed',
        'production', 'cinema', 'watch', 'see', 'view', 'screen',
        'featuring', 'based', 'follows', 'tells', 'depicts', 'portrays',
        'chronicles', 'explores', 'reveals', 'discovers', 'finds',
        'becomes', 'gets', 'goes', 'comes', 'takes', 'makes', 'gives',
        'min', 'minutes', 'hour', 'hours', 'time', 'year', 'years',
        'new', 'old', 'young', 'big', 'small', 'great', 'good', 'bad',
        'best', 'worst', 'first', 'last', 'next', 'previous'
    ]
    return movie_stopwords

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print("ë°ì´í„° ë¡œë”© ì¤‘...")
if not os.path.exists('../movies_with_enhanced_tags.csv'):
    df = pd.read_csv('../video.csv')
    df = preprocess_dataframe(df)

    print(f"ì „ì²´ ë°ì´í„° ìˆ˜: {len(df)}")
    print("ìƒ˜í”Œ ë°ì´í„°:")
    print(df.head())

    # NaN ê°’ë“¤ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    df = df.fillna('')

    print("\ní–¥ìƒëœ íƒœê·¸ ìƒì„± ì¤‘...")
    df['enhanced_tags'] = df.apply(create_enhanced_tags, axis=1)

else:
    df = pd.read_csv('../movies_with_enhanced_tags.csv')

# ìƒì„±ëœ íƒœê·¸ í™•ì¸
print("\nìƒì„±ëœ íƒœê·¸ ìƒ˜í”Œ:")
for i in range(3):
    print(f"\nì œëª©: {df.iloc[i]['title']}")
    print(f"íƒœê·¸: {df.iloc[i]['enhanced_tags'][:200]}...")

# ìµœì í™”ëœ TF-IDF ë²¡í„°ë¼ì´ì € ì„¤ì •
print("\nìµœì í™”ëœ TF-IDF ë²¡í„°ë¼ì´ì € ì„¤ì • ì¤‘...")

# ì˜í™” ë„ë©”ì¸ íŠ¹í™” ë¶ˆìš©ì–´
movie_stopwords = get_enhanced_stopwords()

# ìµœì í™”ëœ TfidfVectorizer
tfidf_optimized = TfidfVectorizer(
    max_features=15000,              # ì •í™•ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•
    min_df=2,                        # ìµœì†Œ 2ê°œ ë¬¸ì„œì— ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ë§Œ (ë…¸ì´ì¦ˆ/ì˜¤íƒ€ ì œê±°)
    max_df=0.85,                     # 85% ì´ìƒ ë¬¸ì„œì— ë‚˜íƒ€ë‚˜ëŠ” ê³¼ë„í•˜ê²Œ ì¼ë°˜ì ì¸ ë‹¨ì–´ ì œê±°
    stop_words=movie_stopwords,      # ì˜í™” ë„ë©”ì¸ íŠ¹í™” ë¶ˆìš©ì–´
    ngram_range=(1, 2),             # ë‹¨ì¼ì–´ + ì´ì¤‘ì–´ ì¡°í•©
    lowercase=True,                  # ëŒ€ì†Œë¬¸ì ì •ê·œí™”
    strip_accents='unicode',         # êµ­ì œ ë¬¸ì ì²˜ë¦¬
    norm='l2',                      # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ìœ„í•œ L2 ì •ê·œí™”
    use_idf=True,                   # IDF ê°€ì¤‘ì¹˜ í™œì„±í™”
    smooth_idf=True,                # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    sublinear_tf=False,             # ì˜í™” ë°ì´í„°ì—ëŠ” ì„ í˜• TFê°€ ë” íš¨ê³¼ì 
    token_pattern=r'\b[a-zA-Z][a-zA-Z_]+\b'  # ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” í† í°ë§Œ ì¸ì‹
)

print("TF-IDF í–‰ë ¬ ìƒì„± ì¤‘...")
tfidf_matrix_optimized = tfidf_optimized.fit_transform(df['enhanced_tags'])

print(f"ìµœì í™”ëœ TF-IDF í–‰ë ¬ í¬ê¸°: {tfidf_matrix_optimized.shape}")
print(f"ì‚¬ìš©ëœ íŠ¹ì„± ìˆ˜: {len(tfidf_optimized.get_feature_names_out())}")

# ëª¨ë¸ ì €ì¥
print("\nëª¨ë¸ ì €ì¥ ì¤‘...")
joblib.dump(tfidf_optimized, '../tfidf_vectorizer_optimized.joblib')
np.save('../tfidf_matrix_optimized.npy', tfidf_matrix_optimized.toarray())
df[['title', 'enhanced_tags']].to_csv('../movies_with_enhanced_tags.csv', index=False)

print("ìµœì í™”ëœ TF-IDF ë²¡í„°ë¼ì´ì €, í–‰ë ¬, íƒœê·¸ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")

# í–¥ìƒëœ ì¶”ì²œ í•¨ìˆ˜
def get_enhanced_recommendations(title, df, tfidf_matrix, top_k=10, diversity_threshold=0.3):
    """ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ í–¥ìƒëœ ì¶”ì²œ"""
    if title not in df['title'].values:
        print(f"'{title}' ì˜í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    idx = df[df['title'] == title].index[0]
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    sim_scores = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()
    
    # ìœ ì‚¬ë„ ì ìˆ˜ì™€ ì¸ë±ìŠ¤ë¥¼ í•¨ê»˜ ì •ë ¬
    sim_indices_scores = [(i, score) for i, score in enumerate(sim_scores) if i != idx]
    sim_indices_scores.sort(key=lambda x: x[1], reverse=True)
    
    # ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ì¶”ì²œ ì„ íƒ
    recommendations = []
    recommended_genres = set()
    
    original_genres = set()
    if pd.notnull(df.iloc[idx]['listed_in']):
        original_genres = {genre.strip().lower() for genre in df.iloc[idx]['listed_in'].split(',')}
    
    for i, (movie_idx, score) in enumerate(sim_indices_scores):
        if len(recommendations) >= top_k:
            break
            
        movie_genres = set()
        if pd.notnull(df.iloc[movie_idx]['listed_in']):
            movie_genres = {genre.strip().lower() for genre in df.iloc[movie_idx]['listed_in'].split(',')}
        
        # ë‹¤ì–‘ì„± ì²´í¬: ë„ˆë¬´ ë¹„ìŠ·í•œ ì¥ë¥´ì˜ ì˜í™”ë§Œ ì¶”ì²œí•˜ì§€ ì•Šë„ë¡
        genre_overlap = len(recommended_genres & movie_genres) / max(len(movie_genres), 1)
        
        if i < top_k // 2 or genre_overlap < diversity_threshold:  # ìƒìœ„ ì ˆë°˜ì€ ë¬´ì¡°ê±´ í¬í•¨, ë‚˜ë¨¸ì§€ëŠ” ë‹¤ì–‘ì„± ê³ ë ¤
            recommendations.append((movie_idx, score))
            recommended_genres.update(movie_genres)
    
    return recommendations

# ê°œì„ ëœ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
print("\n=== ê°œì„ ëœ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")

# ë‹¤ì–‘í•œ ì¥ë¥´ì˜ ì˜í™”ë“¤ë¡œ í…ŒìŠ¤íŠ¸
test_movies = [
    'Sankofa',                        # Movie
    'The Great British Baking Show',  # TV Show  
    'The Starling',                   # Movie
    'Je Suis Karl',                   # Movie
    'Jeans',                          # Movie
    'Grown Ups',                      # Movie
    'Dark Skies',                     # Movie
    'Paranoia',                       # Movie
    'Birth of the Dragon',            # Movie
    'Jaws'                           # Movie
]

for title in test_movies:
    if title in df['title'].values:
        print(f"\n{'='*60}")
        print(f"ğŸ¬ [{title}]ì™€ ìœ ì‚¬í•œ ì˜í™” TOP 5 (ê°œì„ ëœ ë²„ì „)")
        print(f"{'='*60}")
        
        # ì›ë³¸ ì˜í™” ì •ë³´
        idx = df[df['title'] == title].index[0]
        original_movie = df.iloc[idx]
        print(f"ì›ë³¸ ì •ë³´:")
        print(f"  ì¥ë¥´: {original_movie['listed_in']}")
        print(f"  ì„¤ëª…: {original_movie['description'][:100]}...")
        if original_movie['director']:
            print(f"  ê°ë…: {original_movie['director']}")
        print()
        
        recommendations = get_enhanced_recommendations(title, df, tfidf_matrix_optimized, top_k=5)
        
        for rank, (movie_idx, score) in enumerate(recommendations, 1):
            movie = df.iloc[movie_idx]
            print(f"{rank}. {movie['title']} (ìœ ì‚¬ë„: {score:.3f})")
            print(f"   ì¥ë¥´: {movie['listed_in']}")
            if movie['director']:
                print(f"   ê°ë…: {movie['director']}")
            print(f"   ì„¤ëª…: {movie['description'][:80]}...")
            print()

# íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
print("\n=== TF-IDF íŠ¹ì„± ë¶„ì„ ===")
feature_names = tfidf_optimized.get_feature_names_out()
print(f"ì´ íŠ¹ì„± ìˆ˜: {len(feature_names)}")

# ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ë“¤ (IDF ê°’ì´ ë‚®ì€ ê²ƒë“¤ = ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ì¤‘ìš”í•œ ë‹¨ì–´ë“¤)
idf_scores = tfidf_optimized.idf_
feature_importance = list(zip(feature_names, idf_scores))
feature_importance.sort(key=lambda x: x[1])

print("\nê°€ì¥ ì¼ë°˜ì ì¸ íŠ¹ì„±ë“¤ (IDF ë‚®ìŒ):")
for feature, idf in feature_importance[:20]:
    print(f"  {feature}: {idf:.3f}")

print("\nê°€ì¥ íŠ¹ë³„í•œ íŠ¹ì„±ë“¤ (IDF ë†’ìŒ):")
for feature, idf in feature_importance[-20:]:
    print(f"  {feature}: {idf:.3f}")

print("\n=== ê°œì„ ì‚¬í•­ ìš”ì•½ ===")
print("1. âœ… ê°€ì¤‘ì¹˜ ê¸°ë°˜ íƒœê·¸ ìƒì„± (ì¥ë¥´ 3ë°°, ì œëª©/ê°ë… 2ë°°)")
print("2. âœ… ê³ ê¸‰ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (êµ¬ë‘ì  ì œê±°, ì •ê·œí™”)")
print("3. âœ… ì˜í™” ë„ë©”ì¸ íŠ¹í™” ë¶ˆìš©ì–´ ì œê±°")
print("4. âœ… n-gram (1,2) í™œìš©ìœ¼ë¡œ ë¬¸ë§¥ í¬ì°©")
print("5. âœ… min_df/max_dfë¡œ ë…¸ì´ì¦ˆ ë° ê³¼ë„í•œ ì¼ë°˜ì–´ ì œê±°")
print("6. âœ… ë‹¤ì–‘ì„± ê³ ë ¤ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜")
print("7. âœ… ë°°ìš°, êµ­ê°€, ì—°ëŒ€ ì •ë³´ í™œìš©")
print("\nì´ì œ í›¨ì”¬ ë” ì •í™•í•˜ê³  ì˜ë¯¸ìˆëŠ” ì¶”ì²œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤! ğŸš€")